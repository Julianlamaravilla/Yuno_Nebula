# ğŸš¨ Sistema de Alertas Mejorado - Yuno Sentinel

## ğŸ“‹ Problema Identificado

El sistema generaba **demasiadas alertas** (tanto WARNING como CRITICAL) por:
- Umbrales muy bajos (1% error rate)
- No diferenciaba entre errores transitorios vs persistentes
- No rastreaba cÃ³digos HTTP especÃ­ficos (500, 501, 502, 503, 504)
- Alertaba por errores que se auto-resolvÃ­an rÃ¡pidamente

## âœ… Soluciones Implementadas

### 1. **DetecciÃ³n de Tendencias Persistentes** (Anti-Falsos Positivos)

**Antes:**
- Alertaba con 1 solo error de cada 100 transacciones

**Ahora:**
- Requiere **8 errores consecutivos** en ventana de 10 minutos
- Verifica que el 60% de las ventanas de tiempo tengan errores
- Solo alerta si es un patrÃ³n **persistente**

```python
# ConfiguraciÃ³n en config.py
min_consecutive_errors: 8
error_trend_window_minutes: 10
```

### 2. **DetecciÃ³n de RecuperaciÃ³n AutomÃ¡tica**

**Nueva funcionalidad:**
- Detecta cuando un proveedor se recupera despuÃ©s de errores
- Requiere 5 transacciones exitosas consecutivas
- Cancela alertas activas automÃ¡ticamente

```python
recovery_check_threshold: 5  # txns exitosas para marcar como recuperado
```

### 3. **AnÃ¡lisis de CÃ³digos HTTP**

**Antes:**
- Solo reportaba "ERROR" sin detalles

**Ahora:**
- Desglose por cÃ³digo de respuesta (500, 502, 503, 504)
- Identifica el cÃ³digo mÃ¡s frecuente
- Recomienda acciones especÃ­ficas por tipo de error

```python
# Ejemplo de output
Response codes: {'504': 45, '502': 12, '500': 3}
Most common: 504 (Gateway Timeout)
Action: "Increase timeout or failover"
```

### 4. **Acciones Recomendadas Inteligentes**

| CÃ³digo HTTP | AcciÃ³n Recomendada |
|-------------|-------------------|
| 504, 503, 502 | Aumentar timeout o failover |
| 500 | Contactar proveedor (error interno) |
| Otros | Pausar trÃ¡fico temporalmente |

### 5. **Umbrales Ajustados**

| MÃ©trica | Antes | Ahora | RazÃ³n |
|---------|-------|-------|-------|
| Error Rate Alert | 1% | 10% | MÃ¡s sensible pero realista |
| Min Transactions | 20 | 30 | Muestra estadÃ­sticamente significativa |
| Alert Cooldown | 5 min | 10 min | Evita spam de alertas |
| CRITICAL Severity | Random 10% | Error > 30% | Basado en impacto real |

## ğŸ¯ Ejemplo de Flujo

### Escenario: 6 errores 500 que se auto-resuelven

**Antes:**
```
1. Error 1 â†’ âŒ Alerta inmediata
2. Error 2 â†’ âŒ Otra alerta (sin cooldown suficiente)
3. Error 3-6 â†’ âŒ MÃ¡s alertas
7. Se recupera â†’ âš ï¸ Sigue mostrando alerta activa
```

**Ahora:**
```
1-7. Errores 1-7 â†’ âœ… No alerta (< 8 consecutivos)
8. Error 8 â†’ âš ï¸ Verifica tendencia
   - Chequea ventana de 10min
   - Verifica si es patrÃ³n persistente
   - âŒ NO alerta (solo 8 errores, no es persistente)
9. Se recupera â†’ âœ… Detecta recuperaciÃ³n automÃ¡tica
```

### Escenario: Problema real persistente con Stripe

**Antes:**
```
Status ERROR - rate 15%
â†’ Alerta genÃ©rica sin detalles
```

**Ahora:**
```
ğŸ” AnÃ¡lisis profundo:
- Error rate: 25% (75/300 txns)
- Tendencia: Persistente (10 min)
- Response codes: {'504': 60, '503': 15}
- Proveedor: STRIPE
- PaÃ­s: MX
- Issuer: BBVA (50/75 errores)

ğŸš¨ ALERTA:
Severity: CRITICAL
Title: "STRIPE MX - Persistent Timeouts (HTTP 504)"
Root Cause: "BBVA issuer especÃ­fico"
Action: "Failover BBVA a dLocal"
```

## ğŸ“Š MÃ©tricas de ReducciÃ³n de Alertas

**Estimado de reducciÃ³n:**
- **Falsos positivos**: -80%
- **Alertas duplicadas**: -60%
- **Alertas sin acciÃ³n**: -70%

**Alertas que SÃ se mantienen:**
- Problemas persistentes reales
- Impacto financiero significativo
- Patrones anÃ³malos confirmados

## ğŸ”§ Archivos Modificados

1. **backend/config.py**
   - Nuevos parÃ¡metros de tendencias
   - Umbrales ajustados

2. **backend/worker.py**
   - `check_error_trend()` - Detecta patrones persistentes
   - `check_recovery()` - Detecta recuperaciÃ³n automÃ¡tica
   - `get_error_code_breakdown()` - Analiza cÃ³digos HTTP
   - `should_alert()` - Cooldown inteligente
   - `determine_root_cause()` - Incluye cÃ³digos de error

## ğŸš€ PrÃ³ximos Pasos Sugeridos

1. **Machine Learning** (futuro):
   - Aprender baseline por merchant
   - DetecciÃ³n de anomalÃ­as con Z-score

2. **Alert Grouping**:
   - Agrupar alertas relacionadas
   - "3 proveedores afectados en MX"

3. **Notification Routing**:
   - CRITICAL â†’ PagerDuty
   - WARNING â†’ Slack
